{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ET5003_KaggleCompetition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "930vlW5BrOtq"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
        "</div> \n",
        "\n",
        "#**Artificial Intelligence - MSc**\n",
        "##ET5003 - MACHINE LEARNING APPLICATIONS \n",
        "\n",
        "###Instructor: Enrique Naredo\n",
        "###ET5003_KaggleCompetition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqXD_IwUQuBF",
        "cellView": "form"
      },
      "source": [
        "#@title Current Date\n",
        "Today = '2021-10-05' #@param {type:\"date\"}\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDKau31OjVO"
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown ### Enter your details here:\n",
        "Team_Number = \"1\" #@param {type:\"string\"}\n",
        "Student_ID_Name = \"20214537 Tom Keane\" #@param {type:\"string\"}\n",
        "Student_ID_Name = \"\" #@param {type:\"string\"}\n",
        "Student_ID_Name = \"\" #@param {type:\"string\"}\n",
        "Student_ID_Name = \"\" #@param {type:\"string\"}\n",
        "Student_ID_Name = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r39xGZckTpKx"
      },
      "source": [
        "#@title Notebook information\n",
        "Notebook_type = 'Etivity' #@param [\"Example\", \"Lab\", \"Practice\", \"Etivity\", \"Assignment\", \"Exam\"]\n",
        "Version = \"Final\" #@param [\"Draft\", \"Final\"] {type:\"raw\"}\n",
        "Submission = False #@param {type:\"boolean\"}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A0Z6S-r6DpA"
      },
      "source": [
        "# INTRODUCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2vlkUAJ7Pz7"
      },
      "source": [
        "Your introduction here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aajlS0WCJ8pm"
      },
      "source": [
        "***The goal is to use advanced Machine Learning methods to predict House price.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg7VCbX77eAA"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFFLThrpwibd"
      },
      "source": [
        "# Suppressing Warnings:\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k96-GLUGE2ux"
      },
      "source": [
        "# standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYPJU_Y6O6Dq"
      },
      "source": [
        "# to plot\n",
        "import matplotlib.colors\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# to generate classification, regression and clustering datasets\n",
        "import sklearn.datasets as dt\n",
        "\n",
        "# to create data frames\n",
        "from pandas import DataFrame\n",
        "\n",
        "# to generate data from an existing dataset\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxMYIOx1FONV"
      },
      "source": [
        "# Scikit-learn is an open source machine learning library \n",
        "# that supports supervised and unsupervised learning\n",
        "# https://scikit-learn.org/stable/\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLlFHWx4j7W6"
      },
      "source": [
        "# Regular expression operations\n",
        "#https://docs.python.org/3/library/re.html\n",
        "import re \n",
        "\n",
        "# Natural Language Toolkit\n",
        "# https://www.nltk.org/install.html\n",
        "import nltk\n",
        "\n",
        "# Stemming maps different forms of the same word to a common “stem” \n",
        "# https://pypi.org/project/snowballstemmer/\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# https://www.nltk.org/book/ch02.html\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cfDHD9BXh0s",
        "outputId": "90d86af7-609b-4362-bd90-7db53d844a4e"
      },
      "source": [
        "!pip install gpy"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpy\n",
            "  Downloading GPy-1.10.0.tar.gz (959 kB)\n",
            "\u001b[K     |████████████████████████████████| 959 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpy) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gpy) (1.15.0)\n",
            "Collecting paramz>=0.9.0\n",
            "  Downloading paramz-0.9.5.tar.gz (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from gpy) (0.29.24)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from gpy) (1.4.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.7/dist-packages (from paramz>=0.9.0->gpy) (4.4.2)\n",
            "Building wheels for collected packages: gpy, paramz\n",
            "  Building wheel for gpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpy: filename=GPy-1.10.0-cp37-cp37m-linux_x86_64.whl size=2565098 sha256=85755a4c368415b8c457164445b5d4f5f4f4033d5f0990cbac7bbfd840eec801\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/18/28/dd1ce0192a81b71a3b086fd952511d088b21e8359ea496860a\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-py3-none-any.whl size=102565 sha256=dcf7b8e9de7df00e501a3dcde90ee8d5942c2abba21c524bba8700ed2a79748d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/95/f5/ce28482da28162e6028c4b3a32c41d147395825b3cd62bc810\n",
            "Successfully built gpy paramz\n",
            "Installing collected packages: paramz, gpy\n",
            "Successfully installed gpy-1.10.0 paramz-0.9.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwGh2bagw4kg"
      },
      "source": [
        "import GPy as GPy\n",
        "import numpy as np\n",
        "import pylab as pb\n",
        "import pymc3 as pm\n",
        "import arviz as az"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MUJdlxSPSMM"
      },
      "source": [
        "# Define the seed so that results can be reproduced\n",
        "seed = 11\n",
        "rand_state = 11\n",
        "\n",
        "# Define the color maps for plots\n",
        "color_map = plt.cm.get_cmap('RdYlBu')\n",
        "color_map_discrete = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"cyan\",\"magenta\",\"blue\"])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL91ShB19RPw"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESg5DGKWJSOf"
      },
      "source": [
        "Extract from this [paper](https://ieeexplore.ieee.org/document/9300074):\n",
        "\n",
        "* House prices are a significant impression of the economy, and its value ranges are of great concerns for the clients and property dealers. \n",
        "\n",
        "* Housing price escalate every year that eventually reinforced the need of strategy or technique that could predict house prices in future. \n",
        "\n",
        "* There are certain factors that influence house prices including physical conditions, locations, number of bedrooms and others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Y2pf50FlYL"
      },
      "source": [
        "1. [Download the dataset](https://github.com/UL-CS6134/CS6134_SEM1_2021-2/tree/main/Week-5). \n",
        "\n",
        "2. Upload the dataset into your folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMkdCQEmKTof"
      },
      "source": [
        "The challenge is to predict the final price of each house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PMoPLlUJ1Ly"
      },
      "source": [
        "## Training & Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loLTHklwKGnV",
        "outputId": "e5ca84c6-09b9-4ca8-f3f2-e180a6004d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "# split data into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# training: 70% (0.7), test: 30% (0.3) \n",
        "# you could try any other combination \n",
        "# but consider 50% of training as the low boundary\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8501f70a64a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# you could try any other combination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# but consider 50% of training as the low boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztBkSZluye87"
      },
      "source": [
        "### Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rosmH4665uJ"
      },
      "source": [
        "# training dataset: \n",
        "training_file = syntPath+filename1\n",
        "# test dataset: \n",
        "testing_file = syntPath+filename2\n",
        "# cost dataset: \n",
        "cost_file = syntPath+filename3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XUFUPABMHfF"
      },
      "source": [
        "# show first data frame rows \n",
        "dftrain.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rq_p-D4yLBe"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "dftrain.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqg9_uxFyZli"
      },
      "source": [
        "### Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw2_yypxMfsi"
      },
      "source": [
        "# show first data frame rows \n",
        "dftest.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXo0x2u7T7-1"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "dftest.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjMH1CSEUA1A"
      },
      "source": [
        "### Expected Cost dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p63sCZeUNx3"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "dfcost.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5oRiZxo2gpN"
      },
      "source": [
        "# NATURAL LANGUAGE PROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8s0Wi3a8yjN"
      },
      "source": [
        "Natural language processing ([NLP](https://en.wikipedia.org/wiki/Natural_language_processing)) is a subfield of linguistics, computer science, and artificial intelligence.\n",
        "\n",
        "* NLP concerned with the interactions between computers and human language.\n",
        "* In particular how to program computers to process and analyze large amounts of natural language data. \n",
        "* The goal is a computer capable of \"understanding\" the contents of documents.\n",
        "* Including the contextual nuances of the language within them. \n",
        "* The technology can then accurately extract information and insights contained in the documents.\n",
        "* As well as categorize and organize the documents themselves. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oValFP-z2gpN"
      },
      "source": [
        "Your comments, explanation, and references here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_WND6NP2gpN"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJFJQxAS9HZK"
      },
      "source": [
        "# PIECEWISE REGRESSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkRchZtf6IV-"
      },
      "source": [
        "**Piecewise regression**, extract from [Wikipedia](https://en.wikipedia.org/wiki/Segmented_regression):\n",
        "\n",
        "Segmented regression, also known as piecewise regression or broken-stick regression, is a method in regression analysis in which the independent variable is partitioned into intervals and a separate line segment is fit to each interval. \n",
        "\n",
        "* Segmented regression analysis can also be performed on \n",
        "multivariate data by partitioning the various independent variables. \n",
        "* Segmented regression is useful when the independent variables, clustered into different groups, exhibit different relationships between the variables in these regions. \n",
        "\n",
        "* The boundaries between the segments are breakpoints.\n",
        "\n",
        "* Segmented linear regression is segmented regression whereby the relations in the intervals are obtained by linear regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po84zvge2NS7"
      },
      "source": [
        "Your comments, explanation, and references here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXX7Mq2Y2NrK"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kFgkUA85_pn"
      },
      "source": [
        "# BAYESIAN NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELer5PV37ftX"
      },
      "source": [
        "A [Bayesian network](https://en.wikipedia.org/wiki/Bayesian_network) (also known as a Bayes network, Bayes net, belief network, or decision network) is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG). \n",
        "\n",
        "* Bayesian networks are ideal for taking an event that occurred and predicting the likelihood that any one of several possible known causes was the contributing factor. \n",
        "* For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. \n",
        "* Given symptoms, the network can be used to compute the probabilities of the presence of various diseases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0kauv1L5_po"
      },
      "source": [
        "Your comments, explanation, and references here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0smpwCET5_pp"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0GYCpwEM09T"
      },
      "source": [
        "# SUMMARY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBDzsZSJ7HZp"
      },
      "source": [
        "Your summary here."
      ]
    }
  ]
}