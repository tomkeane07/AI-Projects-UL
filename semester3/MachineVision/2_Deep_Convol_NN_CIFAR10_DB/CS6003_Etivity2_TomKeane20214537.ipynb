{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Etivity_assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyscan6003/CE6003/blob/master/Etivity_assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMd1Rc3eDwBP"
      },
      "source": [
        "# Etivity 2: Deep Convolutional Neural Network on CIFAR-10 Dataset\n",
        "\n",
        "In this assignment, we will gain some practical experience of coding a deep convolutional neural network in Tensorflow. The simplest way to code a network is to use the High level Keras API within Tensorflow 2.5.  \n",
        "\n",
        "## (a) Introduction\n",
        "\n",
        " In this assignment to reduce training time and computation, we will train our network using the simple [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset.\n",
        "![link text](https://paperswithcode.com/media/datasets/CIFAR-10-0000000431-b71f61c0_U5n3Glr.jpg)\n",
        "\n",
        "The goal of this Etivity is to build and train your own Deep Convolutional Neural Network. This notebook contains standard keras/Tensorflow code to perform data processing, training set up and testing metrics, as outlined in the steps below. This will allow you to focus on developing the architecture & code for your network. \n",
        "\n",
        "1. Load Dataset - We will import the CIFAR-10 Dataset using the Tensorflow Data Set API.\n",
        "2. Prepare Data - We will slightly modify the dataset before it is sent to the model for training.\n",
        "3. Model Coding - We will write code to build the model using the Tensorflow keras API.\n",
        "  * **You will code your neural network model in this section**\n",
        "4. Compile Model - We will complile the model and verify that it has been correctly constructed.\n",
        "5. Train Model - We will train the model using the imported dataset.\n",
        "6. Test Model - We test the model on the training data and obtain a classification report and confusion matrix.\n",
        "\n",
        "The principal resource for understanding the basics of how to code & train Deep Convolutional Neural Network architectures in Tensorflow/keras are the Tensorflow tutorials. Tutorials on [image classification](https://www.tensorflow.org/tutorials/images/classification) and [data augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation) are useful for this Etivity.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKjhi09Kfwem"
      },
      "source": [
        "\n",
        "## (b) Notes on Architecture selection & development\n",
        "\n",
        "A key task in this Etivity is selecting an appropriate architecture. You can base your archicture on any of the types seen in the lecture notes or published literature. It is however recommended to ensure you can get a standard CNN type architecture to successfully train before attempting a more complex architecture or adding further enhancements to your network to improve performance.\n",
        "   Many published networks are designed to work with larger sized input images (e.g. 224 x 224). Often large (e.g. 7 x 7) convolution kernels and pooling layers are first applied to the input image, which agressively reduce the spatial dimensions of the network. As the CIFAR-10 dataset only has 32 x 32 images, it is recommended that just an intial 3 x 3 convolution is applied to the input image (as shown in the figure below), which will preserve the spatial dimensions of the input, before any other layers are added. It is expected that as you add more layers to the network the spatial dimensions will reduce and there will also be a corresponding increase the number of channels of the output feature map. The architecture will end with a [global average pooling layer](https://arxiv.org/pdf/1312.4400.pdf) and a fully-connected layer (called a *dense* layer in Keras/Tensorflow) with softmax activation which gives us our 10 class predictions. A skeleton code has been provided for any general architure using this structure in section 3.\n",
        "![link text](https://github.com/tonyscan6003/CE6003/blob/master/images/Architecture_outline.jpg?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-usCVtcvZ1jF"
      },
      "source": [
        "#House Keeping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCZcWwiaDOGa"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4odR82ILcVxX"
      },
      "source": [
        "To ensure this assignment runs as fast as possible, from the menu above select **Edit > Notebook settings** or **Runtime > Change runtime type** and select GPU as the Hardware accelerator option.\n",
        "\n",
        "Let's test that we are running using the GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf087-5LcYXc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2f006047-5dcd-4326-985f-c7f9f31cf790"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1AqzPcvPIMZ"
      },
      "source": [
        "#1. Load Dataset\n",
        "\n",
        "In this assignment, we will be using the [CIFAR-10 dataset](http://www.cs.toronto.edu/~kriz/cifar.htmlhttps://). CIFAR-10 is often used as a \"Hello World\" dataset that is often used to ensure a network architecture is working before moving on to training with more complex datasets.\n",
        "\n",
        "The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes (airplane, automobile, **bird**, cat, deer, dog, frog, horse, ship, truck), with 6,000 images per class. There are 50,000 training images and 10,000 test images. \n",
        "\n",
        "We will use the [Tensorflow dataset](https://www.tensorflow.org/datasets/catalog/cifar10) API to download the CIFAR10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBHnROl5fL2B"
      },
      "source": [
        "batch_size = 32 # Default Batch size (can be adjusted)\n",
        "H_trg =32       # Image Height (fixed)\n",
        "W_trg =32       # image Width (fixed)\n",
        "\n",
        "# Labels corresponding to categories\n",
        "label_str = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld6vWvOVeqN0"
      },
      "source": [
        "# We initally load the raw training/validation/test dataset\n",
        "import tensorflow_datasets as tfds\n",
        "ds,info= tfds.load(\"cifar10\",with_info=True)\n",
        "\n",
        "raw_train = tfds.load('cifar10', split='train[0%:90%]')\n",
        "raw_val = tfds.load('cifar10', split='train[91%:100%]')\n",
        "raw_test = tfds.load('cifar10', split='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B4yeoJHft0Y"
      },
      "source": [
        "# 2. Prepare Data\n",
        "\n",
        "After importing raw datasets using tfds load, we create an input pipeline that processes & batches this data before it is supplied to the model for training using the virtual machine GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6PNR8vgetEi"
      },
      "source": [
        "\n",
        "def data_pipe(image,label):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
        "  image = image-0.5\n",
        "  label = tf.cast(label, tf.float32)\n",
        "  return image,label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNzCKI8ffVSK"
      },
      "source": [
        "def gen_tr_datasets(src_dataset):    \n",
        "    # Define Datasets \n",
        "    #src_dataset = src_dataset.shuffle(num_train_examples) \n",
        "    tr_dataset = src_dataset.map(lambda x: (x['image'],x['label']))  \n",
        "    tr_dataset = tr_dataset.map(data_pipe)\n",
        "    tr_dataset = tr_dataset.batch(batch_size) \n",
        "    return tr_dataset\n",
        "\n",
        "def gen_val_datasets(src_dataset): \n",
        "    # Define Datasets \n",
        "    test_dataset = src_dataset.map(lambda x: (x['image'],x['label']))  \n",
        "    test_dataset = test_dataset.map(data_pipe)\n",
        "    test_dataset = test_dataset.batch(batch_size) \n",
        "    return test_dataset\n",
        "# Generate the datasets\n",
        "train_dataset = gen_tr_datasets(raw_train)\n",
        "val_dataset = gen_val_datasets(raw_val)\n",
        "test_dataset = gen_val_datasets(raw_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj_HusiXhura"
      },
      "source": [
        "Plot some examples of the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4N4NNA9fZMU"
      },
      "source": [
        "i=0\n",
        "n_plots = 12 # number of plots\n",
        "f, axarr = plt.subplots(1,n_plots,figsize=(20,10))\n",
        "\n",
        "for image, label in train_dataset.take(n_plots):  # Only take a single example\n",
        "  axarr[i].imshow(image[0,:,:,:]+128)\n",
        "  axarr[i].axis('off')\n",
        "  axarr[i].title.set_text(label_str[int(label[0])])\n",
        "  i = i+1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfRKrY53rCdh"
      },
      "source": [
        "# 3. Model Coding\n",
        "\n",
        "In this section You may develop your own model architecture to perform image recognition with the CIFAR-10 Dataset.\n",
        "\n",
        "There are some recommendations and helper code in this section that you may choose use, or you can also use your own approach to creating your architecture. \n",
        "\n",
        "Please Leave a note at the end of the notebook explaining your approach/results for the e-moderator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or_1E25YFrdA"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "## Note 1: Keras Function/Sequential API\n",
        "\n",
        "Within Keras there are two API's for coding network models: Sequential and functional. You may have already used the [seqential model](https://https://www.tensorflow.org/guide/keras/sequential_model) to code basic artifical neural networks. The [functional model](https://www.tensorflow.org/guide/keras/functional) is more general and enables us to include feedforward paths which are required to code more advanced networks such as ResNet or DenseNet. The functional API has been used to code the helper functions repeating unit/top level skeleton detailed below.\n",
        "\n",
        "## Note 2: Repeating Unit\n",
        "\n",
        "In many Deep architectures there will often be a repeating unit(s) that is composed of a sequence of layers, for example Conv,ReLU & Batch Normalisation. Specific layers can be turned on or off as required. This also allows experimentation of the entire architecture with/without specific layers (e.g. Batch Normalisation)  You may wish to create other combinations of layers or additional repeating units depending on your architecture.\n",
        "\n",
        "In the code cell below we can see an example of a `repeat_unit` function where the number of kernel filters and kernel size is specified. Batch Normalisation and activation layers can be turned on/off as required.\n",
        "\n",
        " * Convolutional Layers are described [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) \n",
        " * Batch Normalization layers are described [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) \n",
        " * Activation layers are described [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Activation) \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFwDIngPfrww"
      },
      "source": [
        "# Example of a Basic Repeating unit\n",
        "\n",
        "def repeat_unit(inputs, num_channels=16, kernel_size=3,\n",
        "                 strides=1, activation='relu', batch_normalization=False):\n",
        "    \"\"\"\n",
        "    inputs: Input to repeat unit.\n",
        "    num_channels: number of channels in convolution layer of repeat unit, nominally = 16\n",
        "    kernel_size: number of kernels to use in convolution, nominally = 3\n",
        "    strides: number of strides for kernel, nominally = 1\n",
        "    activation: type of activation applied to output of convolution, nominally ReLU. \n",
        "    x = output of repeat_unit\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_channels, kernel_size=kernel_size, strides=strides, padding='same',\n",
        "                  kernel_initializer='he_normal')\n",
        "    x = conv(inputs)\n",
        "    \n",
        "    if activation is not None:\n",
        "        x = Activation(activation)(x)\n",
        "\n",
        "    if batch_normalization:\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFvVHWvWagSN"
      },
      "source": [
        "## Note 3: Top Level\n",
        "\n",
        "In the code cell below, an incomplete skeleton function is provided for your top level.  \n",
        "* This uses the Keras functional API\n",
        "* A single repeating unit which does not reduce the spatial dimensions of the input is placed at the top of the stack. You can change the number of channels/kernel size to suit your own architecture.\n",
        "* You can add your own layers/repeating units etc to build your own architecture with the function.\n",
        "* At the end of the stack we add a [global average pooling layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) and fully connected [(Dense)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer with softmax activation. (Alternatively to the Global Average pooling Dense layers can be used, this approach uses more parameter (memory) and is commonly seen in earlier Deeep Learning architectures such as AlexNet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwPACVhkf0uF"
      },
      "source": [
        "\n",
        "def network_top(input_shape,num_classes=10):\n",
        "    \"\"\"\n",
        "    input Shape: (Define H,W, no. channels) of network input\n",
        "                 used in Input definition below\n",
        "    num_classes: Default = 10, sets output classes of network,\n",
        "                 set to same no. of classes as CIFAR 10 Dataset \n",
        "    model:       keras Model returned by this function.                          \n",
        "    \"\"\"\n",
        "       \n",
        "    # Define input of model\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Add First repeating Unit\n",
        "    x = repeat_unit(inputs=x, num_channels=12)\n",
        "  \n",
        "\n",
        "   ######## Add more layers/repeating units to build your Architecture here ##################  \n",
        "\n",
        "\n",
        "    # Add final stages. (Ensure that you call the output of the very last layer outputs)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(x)\n",
        "\n",
        "    # Model definition\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "661APuAef2p4"
      },
      "source": [
        "# 4. Compile the Model\n",
        "Now that we have defined our functions to create the model, we'll instantiate the model and compile it.  Note that the compiling step in Keras, also configures the model for training. We define  loss function, the optimizer and metrics. \n",
        "\n",
        "Note the use here of [Sparse Categorical Crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy). This loss function allows us to input integer values for true classes. With the regular categorical cross entropy loss function the supplied labels must be frist converted to a one-hot representation,  but this special loss function allows us to avoid manually converting to the one-hot representation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyCg5D0sf6E1"
      },
      "source": [
        "input_shape = (32,32,3)\n",
        "model = network_top(input_shape=input_shape)\n",
        "model.compile(loss='SparseCategoricalCrossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Uncomment the following line to plot the model visually - warning this may be quite large!\n",
        "# keras.utils.plot_model(model, dpi=48)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzfMkJAUgT5l"
      },
      "source": [
        "# 5. Model Training\n",
        "\n",
        "We will now train the complied model on the cifar10 dataset using the tensorflow keras `model.fit` method. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9LcX-rwPbxR"
      },
      "source": [
        "epochs =55\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FZ6cNvVf_bz"
      },
      "source": [
        "We will plot the loss and accuracy for the training and validation data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHas5bv9gAlc"
      },
      "source": [
        "print(history.history.keys())\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,2.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e16_Awsoeg8"
      },
      "source": [
        "# 6. Model Testing\n",
        "We will iterate through the test data and analyse the results using tools from sklearn. We create a classification report, a confusion matrix and also plot a few examples from the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puBxU_hoXHP2"
      },
      "source": [
        "Iterate through n_test batches and store the predicted and ground truth labels in numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFavqJx2U0lP"
      },
      "source": [
        "n_test = 100 # number of batches to use\n",
        "store_predictions = []\n",
        "store_labels = []\n",
        "for image_batch,label_batch in test_dataset.take(n_test):\n",
        "    predictions = model.predict_on_batch(image_batch) \n",
        "    predictions = tf.math.argmax(predictions,axis=1)\n",
        "    store_predictions.append(predictions)\n",
        "    store_labels.append(label_batch)\n",
        "y_pred = np.squeeze(np.reshape(store_predictions,(1,n_test*batch_size)))\n",
        "y_true = np.squeeze(np.reshape(store_labels,(1,n_test*batch_size)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m30l3ZrqXy9O"
      },
      "source": [
        "Create and plot a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_C6iDxCVBdu"
      },
      "source": [
        "#https://scikit-learn.org/0.16/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(label_str))\n",
        "    plt.xticks(tick_marks, label_str, rotation=45)\n",
        "    plt.yticks(tick_marks, label_str)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouFy9VtvYA9X"
      },
      "source": [
        "Generate & print the classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAIH0ehnX63_"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred, target_names=label_str))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsc0re0gW-AQ"
      },
      "source": [
        "Plot some test images and predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgFicmYTsun7"
      },
      "source": [
        "#Retrieve a batch of images from the test set\n",
        "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
        "predictions = model.predict_on_batch(image_batch)\n",
        "print(np.shape(predictions))\n",
        "# Apply a sigmoid since our model returns logits\n",
        "predictions = tf.math.argmax(predictions,axis=1)\n",
        "print(np.shape(predictions))\n",
        "print('Predictions:\\n', predictions.numpy())\n",
        "\n",
        "\n",
        "i=0\n",
        "n_plots = 12 # number of plots\n",
        "f, axarr = plt.subplots(1,n_plots,figsize=(20,10))\n",
        "\n",
        "for image in image_batch[0:n_plots,:,:,:]:  # Only take a single example\n",
        "  axarr[i].imshow(image[:,:,:]+0.5)\n",
        "  axarr[i].axis('off')\n",
        "  \n",
        "  color = ('black' if predictions[i] == int(label_batch[i]) else 'red') \n",
        "  axarr[i].set_title(label_str[int(predictions[i])],fontsize='small', color=color)\n",
        "  i = i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBcUifu4dSIt"
      },
      "source": [
        "# Please Leave a note here explaining your approach/results for the e-moderator.\n",
        "\n"
      ]
    }
  ]
}