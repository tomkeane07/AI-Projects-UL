{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ET5003_Etivity2_template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "930vlW5BrOtq"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
        "</div> \n",
        "\n",
        "#**Artificial Intelligence - MSc**\n",
        "##ET5003 - MACHINE LEARNING APPLICATIONS \n",
        "\n",
        "###Instructor: Enrique Naredo\n",
        "###ET5003_Etivity-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqXD_IwUQuBF",
        "cellView": "form"
      },
      "source": [
        "#@title Current Date\n",
        "Today = '2021-08-22' #@param {type:\"date\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDKau31OjVO",
        "cellView": "form"
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown ### Enter your details here:\n",
        "Student_ID = \"\" #@param {type:\"string\"}\n",
        "Student_full_name = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r39xGZckTpKx",
        "cellView": "form"
      },
      "source": [
        "#@title Notebook information\n",
        "Notebook_type = 'Example' #@param [\"Example\", \"Lab\", \"Practice\", \"Etivity\", \"Assignment\", \"Exam\"]\n",
        "Version = 'Draft' #@param [\"Draft\", \"Final\"] {type:\"raw\"}\n",
        "Submission = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A0Z6S-r6DpA"
      },
      "source": [
        "# INTRODUCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkRchZtf6IV-"
      },
      "source": [
        "**Piecewise regression**, extract from [Wikipedia](https://en.wikipedia.org/wiki/Segmented_regression):\n",
        "\n",
        "Segmented regression, also known as piecewise regression or broken-stick regression, is a method in regression analysis in which the independent variable is partitioned into intervals and a separate line segment is fit to each interval. \n",
        "\n",
        "* Segmented regression analysis can also be performed on \n",
        "multivariate data by partitioning the various independent variables. \n",
        "* Segmented regression is useful when the independent variables, clustered into different groups, exhibit different relationships between the variables in these regions. \n",
        "\n",
        "* The boundaries between the segments are breakpoints.\n",
        "\n",
        "* Segmented linear regression is segmented regression whereby the relations in the intervals are obtained by linear regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aajlS0WCJ8pm"
      },
      "source": [
        "***The goal is to use advanced Machine Learning methods to predict House price.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg7VCbX77eAA"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFFLThrpwibd"
      },
      "source": [
        "# Suppressing Warnings:\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1770_fNrCWn"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pymc3 as pm\n",
        "import arviz as az\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYPJU_Y6O6Dq"
      },
      "source": [
        "# to plot\n",
        "import matplotlib.colors\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# to generate classification, regression and clustering datasets\n",
        "import sklearn.datasets as dt\n",
        "\n",
        "# to create data frames\n",
        "from pandas import DataFrame\n",
        "\n",
        "# to generate data from an existing dataset\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MUJdlxSPSMM"
      },
      "source": [
        "# Define the seed so that results can be reproduced\n",
        "seed = 11\n",
        "rand_state = 11\n",
        "\n",
        "# Define the color maps for plots\n",
        "color_map = plt.cm.get_cmap('RdYlBu')\n",
        "color_map_discrete = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"cyan\",\"magenta\",\"blue\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL91ShB19RPw"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESg5DGKWJSOf"
      },
      "source": [
        "Extract from this [paper](https://ieeexplore.ieee.org/document/9300074):\n",
        "\n",
        "* House prices are a significant impression of the economy, and its value ranges are of great concerns for the clients and property dealers. \n",
        "\n",
        "* Housing price escalate every year that eventually reinforced the need of strategy or technique that could predict house prices in future. \n",
        "\n",
        "* There are certain factors that influence house prices including physical conditions, locations, number of bedrooms and others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Y2pf50FlYL"
      },
      "source": [
        "1. [Download the dataset](https://github.com/UL-ET5003/ET5003_SEM1_2021-2/tree/main/Week-3). \n",
        "\n",
        "2. Upload the dataset into your folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMkdCQEmKTof"
      },
      "source": [
        "The challenge is to predict the final price of each house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PMoPLlUJ1Ly"
      },
      "source": [
        "## Training & Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loLTHklwKGnV"
      },
      "source": [
        "# split data into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# training: 70% (0.7), test: 30% (0.3) \n",
        "# you could try any other combination \n",
        "# but consider 50% of training as the low boundary\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztBkSZluye87"
      },
      "source": [
        "### Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rosmH4665uJ"
      },
      "source": [
        "# training dataset: \n",
        "training_file = syntPath+filename1\n",
        "# test dataset: \n",
        "testing_file = syntPath+filename2\n",
        "# cost dataset: \n",
        "cost_file = syntPath+filename3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XUFUPABMHfF"
      },
      "source": [
        "# show first data frame rows \n",
        "dftrain.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rq_p-D4yLBe"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "dftrain.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqg9_uxFyZli"
      },
      "source": [
        "### Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw2_yypxMfsi"
      },
      "source": [
        "# show first data frame rows \n",
        "dftest.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXo0x2u7T7-1"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "dftest.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjMH1CSEUA1A"
      },
      "source": [
        "### Expected Cost dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p63sCZeUNx3"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "dfcost.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJFJQxAS9HZK"
      },
      "source": [
        "# PIECEWISE REGRESSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ_1QsLToIDi"
      },
      "source": [
        "## Full Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv5j1KzzMUnm"
      },
      "source": [
        "# select some features columns just for the baseline model\n",
        "# assume not all of the features are informative or useful\n",
        "# in this exercise you could try all of them if possible\n",
        "\n",
        "featrain = ['feature_1','feature_2','feature_3','cost']\n",
        "# dropna: remove missing values\n",
        "df_subset_train = dftrain[featrain].dropna(axis=0)\n",
        "\n",
        "featest = ['feature_1','feature_2','feature_3']\n",
        "df_subset_test  =  dftest[featest].dropna(axis=0)\n",
        "\n",
        "# cost\n",
        "df_cost = df_cost[df_cost.index.isin(df_subset_test.index)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZK2kfygoIDi"
      },
      "source": [
        "# model\n",
        "with pm.Model() as model:\n",
        "    #prior over the parameters of linear regression\n",
        "    alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
        "    #we have one beta for each column of Xn\n",
        "    beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn_train.shape[1])\n",
        "    #prior over the variance of the noise\n",
        "    sigma = pm.HalfCauchy('sigma_n', 5)\n",
        "    #linear regression model in matrix form\n",
        "    mu = alpha + pm.math.dot(beta, Xn_train.T)\n",
        "    #likelihood, be sure that observed is a 1d vector\n",
        "    like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn_train[:,0])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIskuS3ToIDk"
      },
      "source": [
        "# prediction\n",
        "ll=np.mean(posterior['alpha']) + np.dot(np.mean(posterior['beta'],axis=0), Xn_test.T)\n",
        "y_pred_BLR = np.exp(yscaler.inverse_transform(ll.reshape(-1,1)))[:,0]\n",
        "print(\"MAE = \",(np.mean(abs(y_pred_BLR - y_test))))\n",
        "print(\"MAPE = \",(np.mean(abs(y_pred_BLR - y_test) / y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_jBBKvtoIDk"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYFvbgYDaEOS"
      },
      "source": [
        "### Full Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iphQ53UE0iVw"
      },
      "source": [
        "# training gaussian mixture model \n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "gmm = GaussianMixture(n_components=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h51OhBV5Z4tY"
      },
      "source": [
        "### Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNvx_KxrLt90"
      },
      "source": [
        "# train clusters\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wTT4220zFNx"
      },
      "source": [
        "# test clusters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXF25ZDYoIDl"
      },
      "source": [
        "## Piecewise Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1e-4ruvaJci"
      },
      "source": [
        "# model_0\n",
        "with pm.Model() as model_0:\n",
        "  # prior over the parameters of linear regression\n",
        "  alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
        "  # we have a beta for each column of Xn0\n",
        "  beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn0.shape[1])\n",
        "  # prior over the variance of the noise\n",
        "  sigma = pm.HalfCauchy('sigma_n', 5)\n",
        "  # linear regression relationship\n",
        "  #linear regression model in matrix form\n",
        "  mu = alpha + pm.math.dot(beta, Xn0.T)\n",
        "  # likelihood, be sure that observed is a 1d vector\n",
        "  like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn0[:,0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHBgUe1pcZQQ"
      },
      "source": [
        "##Simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSEdYAUoIDn"
      },
      "source": [
        "### Only Cluster 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgMUwBO7oIDq"
      },
      "source": [
        "## Overall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMY9rDvVoIDq"
      },
      "source": [
        "## Test set performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGmB9BNkoIDr"
      },
      "source": [
        "### PPC on the Test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0GYCpwEM09T"
      },
      "source": [
        "# SUMMARY"
      ]
    }
  ]
}