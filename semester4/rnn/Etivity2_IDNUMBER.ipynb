{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-tivity 2 (07/02/22 - 20/02/22)\n",
    "\n",
    "* Your Name\n",
    "\n",
    "* Your Student ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "This e-tivity is split into two parts. The first part <a href=\"#part1\">**Stock Predicition**</a> is a group activity where you are tasked with predicting the stock market.\n",
    "\n",
    "The second <a href=\"#part2\">**Sentiment Analysis**</a> is an individual task, the problem is to predict if a film review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines\n",
    "\n",
    "The e-tivity is split into five tasks. The first four are \"group\" excersises, in that you post the solutions to Tasks 1-4 to Gitlab. This will allow the members of your group to send you feedback (via the forums) so you can improve your submission. The final task is an individual task and together with the other tasks, should be uploaded to Sulis but not to gitlab.\n",
    "\n",
    "Marks will be deducted if task 5 is posted to gitlab in contravention of instructions. Also if the the final submission is not a single notebook with tasks 1-5 and with correct identification or filename.\n",
    "\n",
    "\n",
    "Grading guidelines: the grades for each task are additive, max 20. Weight [5/7]\n",
    "\n",
    "**Task 1 [0-6]**: Complete with suitable preprocessing steps.\n",
    "\n",
    "**Task 2 [0-4]**: Complete with suitable treatment of missing values. \n",
    "\n",
    "**Tasks 3+4 [0-4]**: Create a suitable model with correct evaluation.\n",
    "\n",
    "**Task 5 [0-6]**: Completion of Task 5, using the layers outlined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "## Stock Prediction\n",
    "\n",
    "### Context\n",
    "\n",
    "There is a small dataset of real stock prices for each working day from the end of 2015 to the end of 2019. There are four variables (with a time stamp), stock price, oil price, gold price and Euro to Dollar exchange. You need to predict the Stock price a day ahead from only the past values of each of the 4 variables. \n",
    "\n",
    "\n",
    "### Tasks 1-4 (complete by Monday 14/02/22)\n",
    "\n",
    "These tasks are to be completed and uploaded to GitLab on which the other group members can comment. The forum activity will form part of the overall mark for the e-tivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1: data preprocessing**\n",
    "\n",
    "Explain any preprocessing steps you take including but limited to reformatting and also how you have selected the training and test sets. The test set should be 20% of the whole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2: data cleaning**\n",
    "\n",
    "There are a number of missing values in the data. Clean the data so that it is suitable for use with the NN. Bare in mind that you want to retain the time coherency of the data as much as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3: model construction**\n",
    "\n",
    "Construct a RNN network that will predict the future value of Stock, one day/time inteval in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: test**\n",
    "\n",
    "Evaluate the model on the test set and display any change in accuracy over time, if any.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post (complete by Monday 14/02/22)\n",
    "\n",
    "Post your solution to Tasks 1-4 in notebook form. If you have not completed all the tasks then that is acceptable. The purpose is to get feedback from others in the group, so if you have only a basic outline then you may get ideas about how to proceed and also examples from others in your group.\n",
    "\n",
    "No posts should reference Task 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respond (complete by Wednesday 16/02/22)\n",
    "\n",
    "If you feel you can provide useful advise then respond to another member of the group through the appropriate forum. Responses should be respectful and offer some sort of advise. Try and avoid clogging the forums with support or thank you messages.\n",
    "\n",
    "In reviewing others code you will discover different ways to tackle the same problem. It is acceptable to copy parts of others code. However whole scale copying from another notebook is not acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grading guidelines for the forum posts: Weight [2/7]\n",
    "\n",
    "**Beginning [0-8]:** Respectful posts of minor value. Significant number of posts without valuable contributions and/or without well-considered questions. Posts about task 5 in contravention of instructions.\n",
    "\n",
    "**Developing [9-12]:** At least 1 post  exceeding Beginning level with respectful suggestion or thought provoking question. Most posts contain valuable contributions or well-considered questions.\n",
    "\n",
    "**Advancing [13-16]:** At least 2 posts: equal to or exceeding Beginning level;  with respectful and sound contribution highlighting mistakes or alternative approaches.\n",
    "\n",
    "**Accomplished [17-20]:** At least 3 posts: equal to or exceeding Accomplished level; with respectful contribution of significant value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "## Sentiment Analysis\n",
    "\n",
    "\n",
    "This task is a individual task and should **not** to be uploaded to GitHub. No direct support should be given via the forums, although comments about progress or results are allowed. Marks will be deducted if the instructions are not followed (see rubrics). This part should be uploaded directly to Sulis.\n",
    "\n",
    "### Context\n",
    "\n",
    "You have a model that predicts the sentiment of a film review (positive or negative) from the IMDB. There are two hyperparameters that format the data from IMDB: the maximum review length and the dictionary size. Below is a RNN model that predicts sentiment values. \n",
    "\n",
    "\n",
    "### Task 5:  (completed by Sunday 20/02/22)\n",
    "\n",
    "Keeping top_words, max_review_lenngth and the embedding_vector_length the same, change the model so that it uses attention only, i.e. there are no recurrent components. The only Keras layers (defined here https://www.tensorflow.org/api_docs/python/tf/keras/layers) that you allowed to use are:\n",
    "- Input,\n",
    "- Embedding, \n",
    "- Dense, \n",
    "- Any Attention (must be at leat one),\n",
    "- TimeDistributed,\n",
    "- Any Merging,\n",
    "- Any Reshaping,\n",
    "- Any Pooling,\n",
    "- Dropout. \n",
    "\n",
    "You need not use any of the layers (except attention) but you can use some more than once. Can you do at least as good as the RNN example?\n",
    "\n",
    "**NB** There are many examples of using attention for sentiment analysis but we looking to see if you can construct a sensible model. The model will be delibrately restricted, so do not waste too much time achieving spectacular accuracy. Remember the rules of thumb that we discussed in the Introduction to DL module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "top_words = 100\n",
    "(Rev_train, Sc_train), (Rev_test, Sc_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(Rev_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(Rev_test, maxlen=max_review_length)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 16\n",
    "model_imdb = Sequential()\n",
    "model_imdb.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
    "model_imdb.add(Dropout(0.2))\n",
    "model_imdb.add(LSTM(10))\n",
    "model_imdb.add(Dropout(0.2))\n",
    "model_imdb.add(Dense(1, activation='sigmoid'))\n",
    "model_imdb.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_imdb.summary())\n",
    "plot_model(model_imdb,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The history for the model above has been saved, as it takes a while to run. If you want to run it yourself then comment out the second line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepoch = 150\n",
    "#IMDB_history = model_imdb.fit(X_train,Sc_train,validation_data=(X_test,Sc_test),epochs=nepoch,batch_size=256)\n",
    "IMDB_history=np.load('IMDBTrainhist.npy',allow_pickle='TRUE').item()\n",
    "plt.plot(range(nepoch),IMDB_history['loss'],c='r')\n",
    "plt.plot(range(nepoch),IMDB_history['val_loss'],c='b')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(nepoch),IMDB_history['accuracy'],c='r')\n",
    "plt.plot(range(nepoch),IMDB_history['val_accuracy'],c='b')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Submission (complete by Sunday 20/02/22)\n",
    "\n",
    "Submit Tasks 1-5 in a single notebook this before the deadline on Sunday.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add additional code cells to implememt the tasks stated above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "There are no specific marks allocated for a reflection. However due consideration will be given if pertinent comments or valuable insights are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
